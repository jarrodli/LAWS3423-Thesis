\let\xn\xnote
\subsection{Procedures}

% TODO: need to add more about why certain methods are applied (overall methodology)
% try to connect between the method and the RQNs.

In order to evaluate the impact of any given academic author or institution on the development of the law, care must be taken to present the gathered data as faithfully and accurately as possible.\xn{4-0} The results will therefore reflect three varied perspectives of academic influence: quantitative metrics, causal inference, and structural rankings. More precisely, we use analytical tools to measure
\begin{enumerate}
    \item the \emph{frequency} of citations to a secondary source;
    \item the \emph{cause} of a trend in citations to a secondary source; and
    \item the \emph{rank} of an author in terms of substantive legal development.
\end{enumerate}
Mindful of the potential issues outlined in Part II, this methodology will attempt to clearly describe each method, as well as explain how it works and why it is used. Overall, this section strives to ensure this study is accessible to both a legal and technical audience, garnering the appearance of lucid discovery rather than indecipherable magic.

\subsubsection{Quantitative Metrics}
Quantitative metrics define a class of methods that attempt to perform measurements based solely on the frequency of a particular event.\xn{4-4} The number of citations to a secondary source in 1998 is an example of a quantitative metric. Equipped with this data, observations will be made about the rate one variable changes $x$ (e.g., year) with respect to another variable $y$ (e.g., the number of citations) to draw a limited set of conclusions\xn{4-5}---for example, that there was an uptake in the use of secondary sources between two years.

The citation data will initially be clustered into four categories for examination, namely by (i) judge, (ii) academic, (iii) article, and (iv) year. As this study aggregates data over multiple years, attention should be drawn to the measurement used. Where appropriate, data is normalised to more accurately represent the incidence of a citation. For instance, the number of years a justice remains on a court can influence the number of judgments written, and therefore the number of opportunities to cite a secondary source.

To these counts, the number of indirect citations will be added. Indirect citations attempt to encompass the number of cases directly citing a paragraph that relies upon a secondary source, thereby indirectly relying on the secondary source in support of a proposition. That the decisions of the High Court are binding on all lower courts prevents direct disagreement with the way in which a secondary source was used.\xn{} \textbf{TODO: can only say this without adding more if we only do HCA, so double check at the end}

We also utilise a well-known quantitative based measure for academic impact called the \emph{h}-index, which quantifies the influence of an academic via the number of works they have written (\emph{h}) that are cited at least \emph{h} times by other authors.\xn{4-5a} While often heavily criticised,\xn{4-5b} the \emph{h}-index offers an objective baseline for measuring the citation impact of an academic. To the extent that the \emph{h}-index is an unsatisfactory measure of academic influence, the network theory algorithms employed in Section C are suitable to control for the problems that arise, such as cases in which an author selectively publishes few articles but to a very high standard. These authors are likely to be frequently cited, but remain constrained by a low \textit{h} publishing score.\xn{}

For the purposes of this study, the rationale behind the \textit{h}-index will be applied as between cited academics and citing judges (henceforth termed the judicial index or `\textit{j}-index'). Accordingly, this study will examine the \emph{j}-index of authors by calculating the number of works (\textit{j}) cited at least \textit{j} times by a judge. The computed table of \emph{j}-indexes will subsequently be assessed against the structural rankings discussed in Section C.

\subsubsection{Causal Inference}
Quantitative approaches raise questions concerning the underlying cause of a trend.\xn{4-6} With the goal of providing an explanation, statistical models will be used to describe the relationship between an explanatory variable $x$ (also known as a covariate) and an outcome $y$.\xn{4-7} Modelling these relationships allows certain conclusions to be made about the identified trends---i.e. whether the covariate and outcome are mutually correlated, or exclusive from one another.\xn{4-7a} Such a relationship can be framed as the independence between judgments and politics, or the correlation between the prospect of bail and whether an accused has a history of violence.

More concretely, this model is defined as an \textit{estimated} linear relationship, where\xn{4-8} \[\hat{y} = \beta_0 + \sum_{i=1}^{n} \beta_ix_i,\]
with parameters $\beta_1, \beta_2, ..., \beta_n$ and $\beta_0$ defining the gradient and intercept of a line `fitted' to the collected data.\xn{4-8a} Simply, this formula adds a constant value $\beta_0$ to a sequence of independent variables $x_1, x_2, ..., x_n$ that are multiplied by a corresponding linear or \textit{estimated} parameter, resulting in: \[\hat{y} = \beta_0 + (\beta_1 \cdot x_1) + (\beta_2 \cdot x_2) + ... + (\beta_n \cdot x_n).\] From this basic model, the number of citations $y$ is readily ascertainable for any set of explanatory variables $x$, irrespective of whether data for that year actually exists.

In practice, modelling this relationship is a generative task because it is impossible to produce a perfect model from a set of sampled data.\xn{4-9} The task is generative in the sense that random variables are generated to explicitly model errors between the model and sampled values.\xn{4-10} A random variable $X$ maps each value $\omega \in \Omega$ (where $\Omega$ is the sample space of all possible outcomes) to a value $v_i = X(\omega_i)$.\xn{4-11} The upshot of introducing random noise is that the observed citation outcomes can be modelled as `realisations' of an \textit{expected distribution} of values. From another perspective, randomness attempts to ensure the modelled data better reflects an expected, or real world, distribution of values.

Selecting the best distribution for a random variable necessitates a review of the types of data collected. In this case, the frequency or count of citation data is a form of \textit{discrete} data.\xn{4-12} Typically, the best distribution (or choice of $X$) for discrete data is the Poisson distribution.\xn{4-13} By adopting a Poisson distribution, a generalised linear model (`GLM') estimates the log mean number of citations to a secondary source, corresponding to\xn{4-14} \[\hat{y} = \log(\hat{\mu}).\]

Although the above GLM can fit statistically independent data, it cannot accurately model data points that are correlated. In Australia, the citation practices of courts do not benefit from independence. For example, opinions frequently split into multiple separate judgments, each constituted by a subset of the coram hearing the case.\xn{4-15} And, as this study describes trends spanning multiple years, the period during which a court sits may also introduce correlation between data points.\xn{4-16}

Linear mixed models (`LLMs') are employed to mitigate against correlative aspects of the citation dataset.\xn{4-17} The independent variables are modelled as explained and are called `fixed' effects.\xn{4-18} The remaining non-independent variables, known as `random' effects, are represented by a sparse matrix of values that group correlated data points together.\xn{4-19} Applying the foregoing principles, the following GLLM is formed\xn{4-20} \[\log(\hat{\mu}) = \beta X + u Y,\] where $x_{ij}$ is an independent variable observing effect $j$ on a data point $i$, and $y_{ij}$ is $1$ if the data point $i$ belongs to group $j$. Taken at its most basic, the above equation represents multiple linear relationships, where the matrix $Y$ groups related data points together, forming a single linear relationship per group.

Where statistical models are created to ascertain causative relationships, \textit{p}-values are used to determine the probability that a fitted variable is equal to or more extreme than its observed value.\xn{4-21} This means that a low \textit{p}-value is exceedingly unlikely under the null-hypothesis---a hypothesis assuming no statistical significance in the observed results. That being so, the observed effects will be considered statistically significant, and the null hypothesis ($\mathrm{H}_0$) will be rejected, if the probability of $\mathrm{H}_0$ is less than 5\%. By convention, a \textit{p}-value less than $0.05$ is accepted as the litmus test for statistical significance.\xn{4-22}

\subsubsection{Structural Rankings}
An issue emerging from measuring academic influence through these quantitative metrics lies in the susceptibility of citation data to unfair and unwanted distortions. For example, a 2019 study found self-citation rates in academic journals to be extremely high, negatively impacting the reliability of quantitative metrics.\xn{} This problem is not novel and was highly influential on the development of tools to prevent tampering with webpage rankings.\xn{} 

More broadly, both examples illustrate a core issue with current practices of measuring an author's impact by way of citations. That is, the evaluative procedure assumes the citing author to be trustworthy. Although it would be misguided to suggest that courts are a priori biased towards citing certain works, unavoidable latent bias in the selection process should be expected. For instance, judges are likely to select publications they can recall from memory, skewing the outcome towards journals that are more oft-read by courts.\xn{} Thus, it remains worthwhile to employ a more objective basis for calculating rankings instead of pure citation counts.

For the purposes of this study, a structural ranking refers to the importance of sources (citing entities) and sinks (cited entities) on the development of substantive law. For instance, in \textit{McCloy},\xn{} Gageler J (source) cites Adrienne Stone (sink).\xn{} In her article, Stone, now the source, cites Elisa Arcioni (sink).\xn{} As Arcioni is also cited by McHugh, Kirby, and Callinan JJ in \textit{Coleman},\xn{} her structural ranking should naturally be higher than the ranking given to Stone. The resulting structure reflecting the source and sink relationships is colloquially termed the ``citation graph''.

The citation graph is generated through a two stage process. Initially, a directed graph is created that represents the entire citation space. Next, 

% \textbf{Then build left eigenvector for matrix $M$ of the stationary probabilities throughout the graph (explain random surfer idea etc.)}

The next section will examine the results of this methodology based on the dataset and procedures outlined above.


% ---
% https://asistdl.onlinelibrary.wiley.com/doi/epdf/10.1002/asi.23179

