\let\xn\xnote
\section{Background}

% TODO: add leading paragraph ..

Given its interdisciplinary nature, this thesis draws heavily on previous work carrying out statistical analyses of judicial decisions. Scholarship in the United States leads the way in the use of statistical methods for validating claims made about judicial behaviour.\xn{2-1} By and large, these articles conduct quantitative surveys of legal information by counting data, noting observations, and providing commentary on identifiable trends.\xn{2-2} However, in Australia, the use of statistics to draw inferences from legal data---e.g., judgments, authorised reports, transcripts, and extralegal literature---about the development of the law is often met with strong disapproval.\xn{2-3} 

While these criticisms are concerning, they are usually not without merit and reveal unacceptably tenuous conclusions in the studies under examination.\xn{2-3a} The reckless use of legal data has thus previously provoked heavy-handed legal responses abroad.\xn{2-3b} In addition to academic criticism, courts remain apprehensive towards statistical methods that critically reflect upon their prior decisions.\xn{2-3ba} So much is clear from recent concerns raised by the Federal Circuit and Family Court of Australia over the statistical analysis of refugee cases.\xn{2-3bb} One might also question the utility of any conclusion formulated using inappropriate statistical methods.

Drawing unsubstantiated conclusions can no doubt seriously undermine public confidence in the judiciary and the legitimacy of future legal scientometric research.\xn{2-3bc} While such damage is likely to vary according to the types of conclusions reached, the standard of work should be set high for any analysis formulating claims and drawing conclusions about the propensity for Australian courts to act in certain ways. In support of a `nuanced approach', the Australian Law Reform Commission recently recommended that courts proactively engage with experts to carry out meaningful statistical analyses of their work.\xn{2-3c}

Whatever the appropriateness of carrying out legal scientometric studies, Smyth has  bucked the domestic aversion to jurimetrics by authoring a number of papers evaluating the citation practices of Australian courts.\xn{2-4} Remarkably, many of these studies employed manual methods to curate the datasets used for conducting longitudinal investigations.\xn{2-5} As the process of manually inspecting legal judgments is exacting on researchers, these studies can only draw conclusions from a small subset of data, compared to the large amounts of available legal information. For example, Smyth and Nielsen attempt to explain High Court citation trends over 115 years with data sampled from only 12 cumulative years of decisions.\xn{2-5a}

Operating under the assumption that this sample space is representative of broad historical trends is problematic, not least because the upshot of a longitudinal study is the minimisation of sampling errors through the use of broader datasets.\xn{2-6} And while this literature recounts general trends,\xn{2-7} few studies venture further to evaluate the impact of authors and journals on the development of the law.\xn{2-8} As mentioned, this could be the result of a chilling effect advanced by eminent jurists.\xn{2-9} However, it may also be attributable to a lack of interdisciplinary interest in this area of research.

In any event, Bennett Moses et al. validly identify these citation analyses to typically be constrained by rudimentary approaches that are unable to evaluate the impact a citation carries from the passage it supports.\xn{2-10} These concerns are echoed by Bowrey, who argues that scientometric studies purporting to measure the impact of journals and authors do not account for the variety of factors influencing the occurrence of a citation.\xn{2-11} For example, it is conceivable that a High Court justice will bias their selection towards an article they previously authored to support an opinion they continue to hold.\xn{2-12} The common denominator of concerns voiced by these authors is a lack of latent information fed into the assessment of academic impact.

Bowrey also encourages an author's position as a laureate professor, fellowship recipient, research only professor, or lecturer to be taken into account insofar as assessments of academic productivity are concerned.\xn{2-12a} Though this might be reasonable in decisions of hiring, promotion, and tenure,\xn{2-12b} it is unsuitable for assessing the degree to which academic literature influences legal development. The reason being, influence should be determined objectively as measured by outcome, rather than a priori based on the opportunity to be influential.

Attempting to reduce the observed ``information gap'', recent literature has applied generalised linear mixed regression models (`GLMMs') to multivariate analyses of court data.\xn{2-13} These models essentially account for a range (multi) of different factors (variate) to approximate the impact of a particular factor---i.e., judge, year, judgment length, and jurisdiction, among others---on the incidence of a citation. Other data science techniques, most notably used by Eigenfactor metrics,\xn{2-14} yield more robust rankings when compared to raw quantitative approaches like the \textit{h}-index.\xn{2-15} We will explore these modern approaches at length in the next Section.
