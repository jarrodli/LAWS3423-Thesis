\let\xn\xnote
\section{Methodology}

% OVERALL METHODOLOGY (answer why + how the follow sections connect to the RQs). / i.e. connect to the introduction

\subsection{Data}

We begin this study by covering the dataset compiled for ingestion by downstream statistical models. First, the initial data collection process is sketched out. Following this, we explore why intermediate manual steps remain in a largely automated collection process. To generalise this collection process, a machine learning model is described that enhances the rudimentary parser with the goal of recognising a broader range of secondary sources. Attention is next drawn to precision issues in the citation practices of courts, prompting a need to examine methods for disambiguating academics by surname. Finally, the reproducibility of results generated by this study is discussed.

\subsubsection{Preparing the dataset}

In Australia, judgments are handed down by courts in the form of legal prose.\xn{3-1} The dissemination of judgments by text poses significant challenges in ascertaining the precise location of a secondary source within a judgment. Reading judgments and spotting references to a secondary source is quite easily completed by humans,\xn{3-2} but this retrieval task does not scale for large amounts of legal information. The obvious solution is to program an automated data collection process, but engineering such a system remains challenging because there is no absolute uniformity in the citation structure of secondary sources.\xn{3-3} 

Fortunately, it remains possible to establish a baseline set of cited secondary material by using the indicative format provided by the Australian Guide to Legal Citation (`AGLC').\xn{3-4} To achieve this, a set of regular expressions (`regex') are developed that match specific patterns of text following AGLC guidelines.\xn{3-5} After applying these regexes to a few sample judgments, they are relaxed to account for slight inaccuracies---e.g., matching on both single and double quotations. A slightly different approach is adopted for collecting books and treatises (collectively `texts'), as there is far less variance in the names of these sources. For the purposes of this study, a predetermined set of 465 texts is used to determine the frequency of citations to textual sources.\xn{3-6}

The above approach is applied to a dataset of judgments spanning 1998 to 2022 indexed by JADE.\xn{3-7} In total, 1483 judgments are parsed.\xn{3-8} From each judgment, the metadata stored includes: (i) the citing judgment date, (ii) a pinpoint to the citing paragraph, (iii) the number of citations to the citing paragraph, (iv) the author, (v) the title of the secondary source, (vi) the year of publication, (vii) the judges citing the secondary source, (viii) the coram size for the judgment, and (ix) the paragraph length of the judgment. For journal articles, additional data on the publishing institution is collected. \textbf{TODO: should step through each data point and explain relevancy}. All data is stored locally in CSV format, colloquially known as a spreadsheet. Overall, 1988 journal articles, and 5389 texts, are identified and stored for further analysis.

\subsubsection{Manual review}

Naturally, the automated parsing of judgments is accompanied by an increase in quality control issues.\xn{3-9} Perhaps the most common source of false positives, or misidentified citations, arises from the use of regexes to identify journal articles. For example, the following statement was identified as a citation, as it matches a relaxed regex pattern:

\begin{center}
when presented for the Royal Assent, ``amend'' the 1947 Act.
\end{center}

In light of these errors, careful manual reviews are conducted on each occasion an automated data ingestion process is run. This study adopts Google's responsible AI practices for collecting data, and in particular the recommendation to ``[w]here possible, directly examine your raw data''.\xn{3-10} To facilitate a systematic review of each data point, the citations are sorted by author name, title, and year so that commonly cited works are grouped together. Grouping data leverages the occurrence of multiple similar citations to decrease the number of direct manual inspections required.

Of course, an obvious question arises: why automate the collection process at all, if a manual review is well within contemplation? The answer is that manually reviewing a few thousand data points is far less demanding compared to manually collecting data from a few thousand decisions. In any case, these reviews are necessary for providing an accurate set of data to generalise the identification process, as outlined in the next section.

\subsubsection{Applying Named Entity Recognition}

Up until this point, a best effort attempt is made to compose regexes that match a large variety of secondary sources. Drawing from the lived experience of researchers and developers at Google, Zinkevich advocates for the adoption of machine learning approaches over complex heuristics.\xn{3-11} While this recommendation is based on issues of maintainability, this study also adopts such an approach to relax the initial manually formulated collection procedure. In this domain, Named Entity Recognition (`NER') is a term used to describe a series of Natural Language Processing techniques that extract and label nouns from structured and unstructured text.\xn{3-12} To generalise the citation extraction process, data collected in the previous sections is used to train an NER model.

More specifically, the regex dataset is used for training an NER model. In aid of this task, the dataset is split in proportions of 90\% for training and 10\% for validation.\xn{3-13} A final scan over each judgment is then completed for the purpose of extracting citations using the trained model. Finally, a second manual review of the final results is undertaken according to the method outlined in the previous section. Ultimately, a well-trained NER model should better identify a more comprehensive range of secondary sources. Such a claim can be confirmed retrospectively as 2281 articles are identified through an NER approach in comparison to 1988 articles with a regex based approach.

\subsubsection{Enriching the dataset}

Another issue with the citation practices of courts is the tendency for judges to identify authors by surname alone.\xn{3-14} Solving this issue requires supplementing the current dataset with information from other sources, a process known as data enrichment.\xn{3-15} To facilitate this process, the journal article citator LawCite\xn{3-16} is used to expand the dataset to include information about each cited author's given name.\xn{3-17} In addition to author name disambiguation, this study leverages LawCite to determine the outgoing citations for each collected journal article. This serves two purposes.

First, the citation graph described in Part IV expands to include academics who are indirectly cited by the court. The assumption here is that expanded models are necessary to recognise that most researchers are ``standing on the shoulders of giants''.\xn{3-18} While this study only examines two degrees of separation between courts and authors, future work should adopt a recursive approach that includes higher degrees of separation but adjusts their authority accordingly. Second, and as a result, the citation graph becomes more ``connected'', in the sense that authors can be associated with both academic and judicial entities. The upshot of greater connectedness is a better contextualised set of results from the algorithms used to rank individual academics.

% Author year of death (to determine whether they were cited while still alive) maybe if I have time, otherwise put it into future work

\subsubsection{Reproducibility}

Final mention should be made to the perennial issue of replicability.\xn{3-19} As a reflection of the Australian legal system, considerable importance must be attributed to the findings of this study and their ability to be scrutinised by the public, much in the same way as the judgments under examination are open to the court of public opinion.\xn{3-20} Furthermore, as the foundation for these claims draw upon freely available legal information,\xn{3-21} it is important that most of the collected data is also freely available. So far as practical, this study intends to ensure that the methods used and results generated are accessible to the research community and wider public.\xn{3-22} As a result, the following data will be re-published online for use as a public resource: \textbf{TODO: what data: x, y, and Z}.\xn{3-23}

% https://search.informit.org/doi/epdf/10.3316/informit.20220201061381
% TODO: remove this
